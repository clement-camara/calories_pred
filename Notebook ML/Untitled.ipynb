{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('/Users/marinelafargue/Desktop/projet calorie/data/best_df_with_age.csv')\n",
    "\n",
    "df_all = pd.read_csv('/Users/marinelafargue/Desktop/projet calorie/data/df_dum.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'height', 'weight', 'Height_meters'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['Unnamed: 0', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X (input) and y (target) features\n",
    "X = df.drop(\"calorie\", axis=1)\n",
    "y = df[\"calorie\"]\n",
    "\n",
    "# Rescale the input features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train test split\n",
    "test_size = 0.33\n",
    "seed = 100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 folds\n",
    "seed = 13\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Create model\n",
    "model_rcv = RidgeCV(cv=kfold)\n",
    "\n",
    "#Fit model\n",
    "model_rcv.fit(X_train, y_train)\n",
    "predictions = model_rcv.predict(X_train)\n",
    "print(\"Train:\", r2_score(y_train, predictions))\n",
    "\n",
    "# Evaluate\n",
    "predictions = model_rcv.predict(X_test)\n",
    "print(\"Test:\", r2_score(y_test, predictions))\n",
    "\n",
    "print(\"Alpha:\", model_rcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 folds\n",
    "seed = 13\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Create model\n",
    "model_lcv = LassoCV(cv=kfold)\n",
    "\n",
    "# Fit model\n",
    "model_lcv.fit(X_train, y_train)\n",
    "predictions = model_lcv.predict(X_train)\n",
    "print(\"Train:\", r2_score(y_train, predictions))\n",
    "\n",
    "# Evaluate\n",
    "predictions = model_lcv.predict(X_test)\n",
    "print(\"Test:\", r2_score(y_test, predictions))\n",
    "\n",
    "print(\"Alpha:\", model_lcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "\n",
    "# Create 5 folds\n",
    "seed = 100\n",
    "kfold = KFold(n_splits=100, shuffle=True, random_state=seed)\n",
    "\n",
    "# Create model\n",
    "#model_lcv = LassoCV(cv=kfold)\n",
    "\n",
    "# Fit model\n",
    "# Instantiation\n",
    "xgb_r = xg.XGBRegressor(objective ='reg:linear',\n",
    "                  n_estimators = 10, seed = 123,cv=kfold)\n",
    "  \n",
    "# Fitting the model\n",
    "xgb_r.fit(X_train, y_train)\n",
    "\n",
    "predictions = xgb_r.predict(X_train)\n",
    "print(\"Train:\", r2_score(y_train, predictions))\n",
    "\n",
    "# Evaluate\n",
    "predictions = xgb_r.predict(X_test)\n",
    "print(\"Test:\", r2_score(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "# Splitting\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                      test_size = 0.3, random_state = 123)\n",
    "  \n",
    "# Train and test set are converted to DMatrix objects,\n",
    "# as it is required by learning API.\n",
    "train_dmatrix = xg.DMatrix(data = train_X, label = train_y)\n",
    "test_dmatrix = xg.DMatrix(data = test_X, label = test_y)\n",
    "  \n",
    "# Parameter dictionary specifying base learner\n",
    "param = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "  \n",
    "xgb_r = xg.train(params = param, dtrain = train_dmatrix, num_boost_round = 10)\n",
    "pred = xgb_r.predict(test_dmatrix)\n",
    "  \n",
    "# RMSE Computation\n",
    "rmse = np.sqrt(MSE(test_y, pred))\n",
    "print(\"RMSE : % f\" %(rmse))\n",
    "\n",
    "mae = np.sqrt(MAE(test_y, pred))\n",
    "print(\"MAE : % f\" %(mae))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart = df_all[['age', 'heart_rate', 'calorie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X (input) and y (target) features\n",
    "X = df_heart.drop(\"calorie\", axis=1)\n",
    "y = df_heart[\"calorie\"]\n",
    "\n",
    "# Rescale the input features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train test split\n",
    "test_size = 0.40\n",
    "seed = 100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:02:45] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:02:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:02:45] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Train: 0.8635815247509054\n",
      "Test: 0.8547960912652972\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "\n",
    "# Create 5 folds\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=100, shuffle=True, random_state=seed)\n",
    "\n",
    "# Create model\n",
    "#model_lcv = LassoCV(cv=kfold)\n",
    "\n",
    "# Fit model\n",
    "# Instantiation\n",
    "xgb_r = xg.XGBRegressor(objective ='reg:linear',\n",
    "                  n_estimators = 10, seed = 123,cv=kfold)\n",
    "  \n",
    "# Fitting the model\n",
    "xgb_r.fit(X_train, y_train)\n",
    "\n",
    "predictions = xgb_r.predict(X_train)\n",
    "print(\"Train:\", r2_score(y_train, predictions))\n",
    "\n",
    "# Evaluate\n",
    "predictions = xgb_r.predict(X_test)\n",
    "print(\"Test:\", r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8261589004210692\n",
      "Test: 0.8288067815809521\n",
      "Alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Create 5 folds\n",
    "seed = 13\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Create model\n",
    "model_rcv = RidgeCV(cv=kfold)\n",
    "\n",
    "#Fit model\n",
    "model_rcv.fit(X_train, y_train)\n",
    "predictions = model_rcv.predict(X_train)\n",
    "print(\"Train:\", r2_score(y_train, predictions))\n",
    "\n",
    "# Evaluate\n",
    "predictions = model_rcv.predict(X_test)\n",
    "print(\"Test:\", r2_score(y_test, predictions))\n",
    "\n",
    "print(\"Alpha:\", model_rcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='r2', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.842 (0.010)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.834 (0.013)\n"
     ]
    }
   ],
   "source": [
    "scores_test = cross_val_score(model, X_test, y_test, scoring='r2', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Mean MAE: %.3f (%.3f)' % (scores_test.mean(), scores_test.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.842 (0.010)\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='r2', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "\n",
    "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svr', SVR(epsilon=0.2))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = regr.score(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
